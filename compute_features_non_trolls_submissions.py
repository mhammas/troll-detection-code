import os
import json
import multiprocessing as mp
import numpy
from multiprocessing import Process, Lock
import csv
import pandas as pd


posts_on_which_trolls_commented = {}
troll_user_dict = {}
all_comment_data = open('/data/hammas/reddit_troll_comments.txt')

for line in all_comment_data:
    post = json.loads(line)
    author = post['author']	
    post_id = post['link_id']
    posts_on_which_trolls_commented[post_id] = 1
    troll_user_dict[author] = 1


posts_which_trolls_started = {}
all_submission_data = open('/data/hammas/reddit_troll_submissions.txt')
troll_title_dict = {}

for line in all_submission_data:
    post = json.loads(line)
    author = post['author']
    link_id = str('t3_' + post['id'])
    title = post['title']
    troll_title_dict[title] = 1
    posts_which_trolls_started[link_id] = 1
    troll_user_dict[author] = 1

#DIR_PATH = '/data/hammas/filtered_comments_again/'
#DIR_PATH = '/data/hammas/filtered_submissions_title_users/'
#DIR_PATH = '/data/hammas/filtered_comments_linkid_troll_posts_all_submissions/'
#DIR_PATH = '/data/hammas/missing_users/'
#DIR_PATH = '/data/hammas/random_accounts/'
DIR_PATH = '/data/hammas/same_title_users_data/'

all_files = []
for file in os.listdir(DIR_PATH):
	if 'submissions' in file:
		all_files.append(file)

def chunks(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

all_files_split = list(chunks(all_files, 1))

print("SUBMISSION ANALYSIS", DIR_PATH)

def my_func(proc_number):
    file_division = all_files_split[proc_number]
    user_dict = {}
    for file_name in file_division:
        print(file_name)
        f = open(DIR_PATH + file_name, 'r')

        for line in f:
            json_line = json.loads(line)
            author = json_line['author']
            title = json_line['title']

            if author not in user_dict:
                user_dict[author] = {"same_title_post_as_troll": 0,
	        						#"same_title_not_autogenerated_post_as_troll": 0,
                                    "total_submissions": 0}

            if title in troll_title_dict:
           		user_dict[author]["same_title_post_as_troll"] += 1

            user_dict[author]['total_submissions'] += 1

    OUTPUT_PATH = '/data/hammas/features/submissions/'
    output_file_name = (DIR_PATH.split('/')[3])

    with open(OUTPUT_PATH + output_file_name + '_' + str(proc_number) +'.csv', 'w', newline='') as csvfile:
	    fieldnames = ['user', 
					'same_title_post_as_troll',
					#'same_title_not_autogenerated_post_as_troll',
	                'total_submissions']

	    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
	    writer.writeheader()

	    for user in user_dict.keys():
	        writer.writerow({"user": user, 
							"same_title_post_as_troll": user_dict[user]["same_title_post_as_troll"],
							#"same_title_not_autogenerated_post_as_troll": user_dict[user]["same_title_not_autogenerated_post_as_troll"],
							"total_submissions": user_dict[user]["total_submissions"]})


pool = mp.Pool(8)
result = pool.map(my_func, [0,1,2,3,4,5,6,7])